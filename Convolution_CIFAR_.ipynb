{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXqUSsvjH2BIZjILuXuMCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BDavidReyesU/Talento-tech/blob/main/Convolution_CIFAR_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJUfUxCzCsKs",
        "outputId": "ec678cdd-c87a-4147-b662-db62da84c554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras import datasets\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.initializers import RandomNormal, Constant\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import gc\n",
        "\n",
        "# Custom Callback To Include in Callbacks List At Training Time\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "\n",
        "# Cargar los conjuntos de datos CIFAR-10 y CIFAR-100\n",
        "(x_train_10, y_train_10), (x_test_10, y_test_10) = datasets.cifar10.load_data()\n",
        "(x_train_100, y_train_100), (x_test_100, y_test_100) = datasets.cifar100.load_data()\n",
        "\n",
        "# Cargar los nombres de las clases para CIFAR-10 y CIFAR-100\n",
        "cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "cifar100_class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
        "\n",
        "# Normalizar los datos de píxeles a un rango entre 0 y 1\n",
        "x_train_10, x_test_10 = x_train_10 / 255.0, x_test_10 / 255.0\n",
        "x_train_100, x_test_100 = x_train_100 / 255.0, x_test_100 / 255.0\n",
        "\n",
        "# Definir el modelo CNN mejorado\n",
        "def create_cnn10_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64,(4,4),input_shape=input_shape,activation='relu'))\n",
        "    model.add(Conv2D(64,(4,4),input_shape=input_shape,activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv2D(128,(4,4),input_shape=input_shape,activation='relu'))\n",
        "    model.add(Conv2D(128,(4,4),input_shape=input_shape,activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024,activation='relu'))\n",
        "    model.add(Dense(1024,activation='relu'))\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def create_cnn100_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(256, (3,3), padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization(momentum=0.95,\n",
        "                                 epsilon=0.005,\n",
        "                                 beta_initializer=RandomNormal(mean=0.0, stddev=0.05),\n",
        "                                 gamma_initializer=Constant(value=0.9)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Función para visualizar la precisión y la pérdida\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Función para mostrar ejemplos de imágenes de prueba junto con las etiquetas reales y las predicciones del modelo\n",
        "def show_examples(images, labels, predictions, class_names):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(int(len(predictions)/5), 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "        actual_label = class_names[labels[i][0]]\n",
        "        predicted_label = class_names[np.argmax(predictions[i])]\n",
        "        if actual_label == predicted_label:\n",
        "            color = 'green'\n",
        "        else:\n",
        "            color = 'red'\n",
        "        plt.xlabel(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\", color=color)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILD MODEL CIFAR10"
      ],
      "metadata": {
        "id": "P5YEHsnKFcdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo CIFAR-10\n",
        "cifar10_model = create_cnn10_model(x_train_10.shape[1:], 10)\n",
        "\n",
        "# Compilar el modelo CIFAR-10\n",
        "cifar10_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo CIFAR-10\n",
        "cifar10_history = cifar10_model.fit(x_train_10, y_train_10, epochs=20, verbose=1, validation_data=(x_test_10, y_test_10))\n",
        "\n",
        "# Visualizar la precisión y la pérdida a lo largo del entrenamiento\n",
        "plot_training_history(cifar10_history)\n",
        "\n",
        "# Evaluar el modelo CIFAR-10\n",
        "test_loss, test_acc = cifar10_model.evaluate(x_test_10, y_test_10, verbose=2)\n",
        "print('\\nCIFAR-10 accuracy:', test_acc)\n",
        "print('\\nCIFAR-10 loss:', test_loss)\n",
        "\n",
        "# Mostrar ejemplos de imágenes de prueba junto con las etiquetas reales y las predicciones del modelo\n",
        "num_examples = 50\n",
        "test_images = x_test_10[:num_examples]\n",
        "test_labels = y_test_10[:num_examples]\n",
        "predictions = cifar10_model.predict(test_images)\n",
        "show_examples(test_images, test_labels, predictions, cifar10_class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-u4-h7-FdI6",
        "outputId": "54d6f5f5-149f-437d-9f7b-f6411a276ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 551/1563 [=========>....................] - ETA: 7:46 - loss: 2.0328 - accuracy: 0.2117"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILD MODEL CIFAR100"
      ],
      "metadata": {
        "id": "ajY5k5erF-R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo CIFAR-100\n",
        "cifar100_model = create_cnn100_model(x_train_100.shape[1:], 100)\n",
        "\n",
        "# Compilar el modelo CIFAR-100\n",
        "cifar100_model.compile(optimizer='adam',\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Preparar el generador de imágenes de datos\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# Crear el conjunto de datos final para el entrenamiento\n",
        "final_dataset = datagen.flow(x_train_100, y_train_100, batch_size=64)\n",
        "\n",
        "# Entrenar el modelo CIFAR-100\n",
        "cifar100_history = cifar100_model.fit(datagen.flow(x_train_100, y_train_100), epochs=20, verbose=1, validation_data=(x_test_100, y_test_100))\n",
        "\n",
        "# Graficar el historial de entrenamiento\n",
        "plot_training_history(cifar100_history)\n",
        "\n",
        "# Evaluar el modelo CIFAR-100\n",
        "test_loss, test_acc = cifar100_model.evaluate(x_test_100, y_test_100, verbose=2)\n",
        "print('\\nCIFAR-100 accuracy:', test_acc)\n",
        "print('\\nCIFAR-100 loss:', test_loss)\n",
        "\n",
        "# Mostrar ejemplos de imágenes de prueba junto con las etiquetas reales y las predicciones del modelo\n",
        "num_examples = 50\n",
        "test_images = x_test_100[:num_examples]\n",
        "test_labels = y_test_100[:num_examples]\n",
        "predictions_100 = cifar100_model.predict(test_images)\n",
        "show_examples(test_images, test_labels, predictions_100, cifar100_class_names)\n"
      ],
      "metadata": {
        "id": "2gijsQd8GBWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}